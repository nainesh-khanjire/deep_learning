{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5820,
     "status": "ok",
     "timestamp": 1672978633739,
     "user": {
      "displayName": "Jitendra Kumar",
      "userId": "00534210576504549633"
     },
     "user_tz": -330
    },
    "id": "ifM8E18oqxFg",
    "outputId": "1d9a1cca-a8f7-4c19-bfac-c3f0d691b0bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading tokenizers/punkt/english.pickle: Package\n",
      "[nltk_data]     'tokenizers/punkt/english.pickle' not found in index\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(temp)  \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create CBOW model\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m                       \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "# importing all necessary modules\n",
    "import nltk.data\n",
    "nltk.download('tokenizers/punkt/english.pickle')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import gensim\n",
    "from gensim.models import Word2Vec  \n",
    "#  Reads ‘alice.txt’ file\n",
    "sample = open(\"../data/alice.txt\", \"r\")\n",
    "s = sample.read()  \n",
    "# Replaces escape character with space\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "data = []\n",
    "# iterate through each sentence in the file\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []    \n",
    "   # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())  \n",
    "    data.append(temp)  \n",
    "# Create CBOW model\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  size = 100, window = 5)                       \n",
    "# Print results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuqgYDyZ9vj9"
   },
   "source": [
    "# Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1672978633739,
     "user": {
      "displayName": "Jitendra Kumar",
      "userId": "00534210576504549633"
     },
     "user_tz": -330
    },
    "id": "dmJuByel9wFk",
    "outputId": "57e527cf-117f-4d28-d275-b6647e59fad6"
   },
   "outputs": [],
   "source": [
    "print(model1.wv.get_vector(\"alice\"))\n",
    "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - CBOW : \", model1.similarity('alice', 'wonderland'))    \n",
    "print(\"Cosine similarity between 'alice' \" + \"and 'machines' - CBOW : \", model1.similarity('alice', 'machines'))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EQ2A0iq9zek"
   },
   "source": [
    "# Skip Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1672978635104,
     "user": {
      "displayName": "Jitendra Kumar",
      "userId": "00534210576504549633"
     },
     "user_tz": -330
    },
    "id": "akJ0HIrn9zuH",
    "outputId": "17e716ce-6416-4383-db56-83dbe40d0e0a"
   },
   "outputs": [],
   "source": [
    "# Create Skip Gram model/content/drive/MyDrive/NLP\n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, window =5, sg = 1)\n",
    "# Print results\n",
    "print(model2.wv.get_vector(\"alice\"))\n",
    "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - Skip Gram : \", model2.similarity('alice', 'wonderland'))      \n",
    "print(\"Cosine similarity between 'alice' \" + \"and 'machines' - Skip Gram : \", model2.similarity('alice', 'machines'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPu3Sbu6Euw/t0+x/oGERcx",
   "mount_file_id": "1WUN_i8Hk7a6B7LmFL-OiPcJQ9NH9xV7r",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
