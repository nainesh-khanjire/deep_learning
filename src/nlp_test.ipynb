{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3d1461-0c7e-4f0c-b9fa-4ad23c50654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Page Not Found</title>\n",
      "<style type=\"text/css\">\n",
      "            a:link { font-family: verdana,arial,helvetica,sans-serif; color: #004B91; }\n",
      "            a:visited { font-family: verdana,arial,helvetica,sans-serif; color: #996633; }\n",
      "            a:active { font-family: verdana,arial,helvetica,sans-serif; color: #FF9933; }\n",
      "        </style>\n",
      "</head>\n",
      "<body bgcolor=\"#FFFFFF\" style=\"font-family: verdana,arial,helvetica,sans-serif;\" text=\"#000000\">\n",
      "<!--\n",
      "            To discuss automated access to Amazon data please contact api-services-support@amazon.com.\n",
      "\n",
      "For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.com/ref=rm_5_sv, or our Product Advertising API at https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html/ref=rm_5_ac for advertising use cases.\n",
      "        -->\n",
      "<center>\n",
      "<a href=\"/ref=cs_404_logo\">\n",
      "<img alt=\"Amazon\" border=\"0\" src=\"https://images-eu.ssl-images-amazon.com/images/G/31/ShoppingPortal/logo._TTD_.png\"/>\n",
      "</a>\n",
      "<table align=\"center\" border=\"0\" style=\"margin-top: 20px;\">\n",
      "<tr>\n",
      "<td>\n",
      "<img border=\"0\" height=\"35\" src=\"https://images-eu.ssl-images-amazon.com/images/G/31/x-locale/common/kailey-kitty._TTD_.gif\" width=\"40\"/>\n",
      "</td>\n",
      "<td>\n",
      "<b style=\"color:#E47911\">Looking for something?</b>\n",
      "<br/>\n",
      "                        We're sorry. The Web address you entered is not a functioning page on our site.\n",
      "                        <br/><br/>\n",
      "<img border=\"0\" height=\"9\" src=\"https://images-eu.ssl-images-amazon.com/images/G/31/x-locale/common/orange-arrow._TTD_.gif\" width=\"10\"/>\n",
      "<b><a href=\"/ref=cs_404_link\">Click here to go back to the Amazon home page</a></b>\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "<!-- 5bdb3e02 -->\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.amazon.in/realme-Mirror-Black-128GB-Storage/product-reviews/B08VB7T9YN/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "print(soup)\n",
    "\n",
    "reviews = soup.find_all('span', {'class': 'a-size-base review-text review-text-content'})\n",
    "\n",
    "for review in reviews:\n",
    "    print(review.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "272c0eb1-f731-4847-811d-0704591ec270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_reviews(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "\n",
    "    # Find all the review containers\n",
    "    review_containers = soup.find_all('div', {'data-hook': 'review'})\n",
    "    print(review_containers)\n",
    "    \n",
    "    # Initialize lists to store positive and negative reviews\n",
    "    positive_reviews = []\n",
    "    negative_reviews = []\n",
    "\n",
    "    # Iterate over each review container\n",
    "    for container in review_containers:\n",
    "        # Extract the rating of the review\n",
    "        rating = container.find('i', {'data-hook': 'review-star-rating'}).text.strip()[0]\n",
    "\n",
    "        # Extract the text of the review\n",
    "        text = container.find('span', {'data-hook': 'review-body'}).text.strip()\n",
    "\n",
    "        # Classify the review as positive or negative based on the rating\n",
    "        if rating in ['4', '5']:\n",
    "            positive_reviews.append(text)\n",
    "        elif rating in ['1', '2']:\n",
    "            negative_reviews.append(text)\n",
    "\n",
    "    return positive_reviews, negative_reviews\n",
    "\n",
    "# Example usage: Get reviews for the first page of results for the \"iPhone\" search query on Amazon\n",
    "url = 'https://buy.realme.com/in/goods/611'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "product_links = soup.find_all('a', {'class': 'a-link-normal a-text-normal'})\n",
    "\n",
    "\n",
    "for link in product_links:\n",
    "    url = 'https://buy.realme.com' + link['href']\n",
    "    positive_reviews, negative_reviews = get_reviews(url)\n",
    "\n",
    "    # Save the positive and negative reviews in separate files\n",
    "    with open('positive_reviews.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(positive_reviews))\n",
    "        f.write('\\n')\n",
    "\n",
    "    with open('negative_reviews.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(negative_reviews))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dcf6746-e038-47d4-8844-d6788a3ea004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\naine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\naine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd55fcd-458a-4f3c-bc8e-a3a3077aab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocessing\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and stem the remaining words\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc51f61-6cfa-4af8-ab98-a6932f485875",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'positive_reviews.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Load and preprocess the data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m positive_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpositive_reviews.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     positive_reviews \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      6\u001b[0m positive_reviews \u001b[38;5;241m=\u001b[39m [preprocess(review) \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m positive_reviews]\n",
      "File \u001b[1;32mD:\\ml2\\ml2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'positive_reviews.txt'"
     ]
    }
   ],
   "source": [
    "# Step 2: Load and preprocess the data\n",
    "\n",
    "positive_reviews = []\n",
    "with open(\"positive_reviews.txt\") as f:\n",
    "    positive_reviews = f.readlines()\n",
    "positive_reviews = [preprocess(review) for review in positive_reviews]\n",
    "\n",
    "negative_reviews = []\n",
    "with open(\"negative_reviews.txt\") as f:\n",
    "    negative_reviews = f.readlines()\n",
    "negative_reviews = [preprocess(review) for review in negative_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f73d34-d0ce-4253-ab6e-c08dfde102ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a training set and a testing set\n",
    "\n",
    "training_set = []\n",
    "training_labels = []\n",
    "\n",
    "testing_set = []\n",
    "testing_labels = []\n",
    "\n",
    "for review in positive_reviews[:500]:\n",
    "    training_set.append(review)\n",
    "    training_labels.append('positive')\n",
    "for review in negative_reviews[:500]:\n",
    "    training_set.append(review)\n",
    "    training_labels.append('negative')\n",
    "\n",
    "for review in positive_reviews[500:600]:\n",
    "    testing_set.append(review)\n",
    "    testing_labels.append('positive')\n",
    "for review in negative_reviews[500:600]:\n",
    "    testing_set.append(review)\n",
    "    testing_labels.append('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf2dfc-e5c0-4c11-a4d1-334359dd85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Vectorize the text\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "training_vectors = vectorizer.fit_transform(training_set)\n",
    "testing_vectors = vectorizer.transform(testing_set)\n",
    "\n",
    "# Step 5: Train and evaluate the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(training_vectors, training_labels)\n",
    "accuracy = clf.score(testing_vectors, testing_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
